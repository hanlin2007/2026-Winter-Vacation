
```python
import torch Â # æ³¨æ„è¿™ä¸ªåŒ…çš„åç§°ï¼Œä¸æ˜¯pytorchï¼Œåé¢éƒ½æ˜¯torch.nnç­‰
import torch.nn as nn
import torch.optim as optim
  

# ç¬¬ä¸€éƒ¨åˆ†ï¼šå‡†å¤‡è®­ç»ƒæ•°æ®
x_train = torch.tensor([[1.0],[2.0],[3.0],[4.0]],device=torch.device('cuda')) # è¾“å…¥å­¦ä¹ æ—¶é—´
y_train = torch.tensor([[3.0],[5.0],[7.0],[9.0]],device=torch.device('cuda')) # è¾“å‡ºå®é™…åˆ†æ•°

# æŸ¥çœ‹GPUæ•°é‡
print(f"GPU count: {torch.cuda.device_count()}")

# æŸ¥çœ‹å½“å‰ä½¿ç”¨çš„GPUåç§°
print(f"current GPU: {torch.cuda.get_device_name(0)}")

# æŸ¥çœ‹æ‰€æœ‰GPUåç§°
for i in range(torch.cuda.device_count()):
    print(f"GPU {i}: {torch.cuda.get_device_name(i)}")

print(x_train)
print(y_train)
print(x_train.device)
print(y_train.device)
print(f"shape show:x={x_train.shape},y={y_train.shape}")
```

```
GPU count: 1
current GPU: NVIDIA GeForce RTX 4050 Laptop GPU
GPU 0: NVIDIA GeForce RTX 4050 Laptop GPU
tensor([[1.],
        [2.],
        [3.],
        [4.]], device='cuda:0')
tensor([[3.],
        [5.],
        [7.],
        [9.]], device='cuda:0')
# è¿™ä¸ªcuda:0ä¸æ˜¯æ²¡æœ‰cudaï¼Œè€Œæ˜¯é»˜è®¤ä½¿ç”¨çš„GPUçš„ç¼–å·ï¼Œåœ¨torch.device('cuda') ä¸­å¯ä»¥æ‰‹åŠ¨æŒ‡å®š
cuda:0   
cuda:0  
shape show:x=torch.Size([4, 1]),y=torch.Size([4, 1])
```

é»˜è®¤åˆ›å»ºçš„å¼ é‡éƒ½æ˜¯ç®€åŒ–åœ¨cpuä¸­çš„ï¼Œéœ€è¦æ‰‹åŠ¨æŒ‡æ˜ä½¿ç”¨GPUæ¥è®­ç»ƒï¼Œå¯ä»¥åç»­ç§»åŠ¨ï¼Œä¹Ÿå¯ä»¥åˆ›å»ºæ—¶ç›´æ¥ä½¿ç”¨cuda

```python

# ç¬¬äºŒéƒ¨åˆ†ï¼šå®šä¹‰æ¨¡å‹ç»“æ„
class LinearRegressionModel(nn.Module):  
    def __init__(self):  
        super().__init__()    
        # å®šä¹‰ä¸€ä¸ªçº¿æ€§å±‚ 
        self.linear = nn.Linear(1,1)    
        
    def forward(self,x);        # æ³¨æ„forwardå‡½æ•°ä¸éœ€è¦æ·»åŠ åŒä¸‹åˆ’çº¿
        return self.linear(x)          
        
# åˆ›å»ºæ¨¡å‹å®ä¾‹
model = LinearRegressionModel()
print(f"initial parameters show:w={model.linear.weight.item():.2f},b={model.linear.bias.item():.2f}")
```

è¿™é‡Œäº§ç”Ÿäº†å¾ˆå¤šé—®é¢˜ï¼Œä¸‹é¢ä¸€ä¸€æ¥è§£å†³å’Œå›ç­”

1.ğŸ‘PyTorch ç¼–ç¨‹çš„æ ¸å¿ƒæ€æƒ³ï¼
åº•å±‚çš„æ•°å­¦å‡½æ•°æ¨¡å‹åŸç†ï¼Œæ¯”å¦‚Linear ReLU Conv2d Pool_max2dç­‰å…¨éƒ¨éƒ½ä½¿ç”¨pytorchå°è£…å¥½äº†ï¼Œåªéœ€è¦è°ƒç”¨å’Œè°ƒæ•´ç½‘ç»œçš„ç»“æ„å°±å¯ä»¥äº†
å› æ­¤ï¼ŒPyTorchç¼–ç¨‹çš„é‡ç‚¹åœ¨äºï¼š
ç†è§£å„ç§å±‚çš„ä½œç”¨ï¼ˆä»€ä¹ˆæ—¶å€™ç”¨ `Linear`ï¼Ÿä»€ä¹ˆæ—¶å€™ç”¨ `Conv2d`ï¼Ÿï¼‰
æŒæ¡ç½‘ç»œç»“æ„è®¾è®¡ï¼ˆå±‚ä¸å±‚ä¹‹é—´å¦‚ä½•è¿æ¥ï¼‰
å­¦ä¼šè°ƒå‚å’Œä¼˜åŒ–
äº†è§£æ•°æ®å¤„ç†å’Œè®­ç»ƒæŠ€å·§

2.åŸºäºç±»åˆ›å»ºå¯¹è±¡
`model = LinearRegressionModel()`
`self.linear = nn.Linear(1,1)`
è¿™ä¸¤ä¸ªéƒ¨åˆ†éƒ½æ˜¯åŸºäºç±»åˆ›å»ºå¯¹è±¡ï¼Œè€Œä¸æ˜¯è°ƒç”¨æˆå‘˜æ–¹æ³•ï¼Œè‡³äºå¯¹è±¡ï¼Œåç»­è¿˜å¯ä»¥ä¼ å…¥å…¶ä»–å‚æ•°ï¼Œåœ¨PyTorchä¸­å¤šä¸º`input_tensor`å‚æ•°ï¼Œæ¯”å¦‚`model(x)`ä»¥åŠ`linear(x)` å‡ä¸ºè¿™ä¸€ç”¨æ³•

3.ä¸ºä»€ä¹ˆåç»­çš„å‰å‘ä¼ æ’­æ²¡æœ‰è°ƒç”¨`forward()`å‡½æ•°ï¼Œè€Œæ˜¯ç›´æ¥ä½¿ç”¨äº†`model(x)`?
`model(x)`çš„å®é™…æ‰§è¡Œä»£ç æ˜¯é­”æ³•æ–¹æ³• `model.__call__(x)`
`nn.Module`ä¸­æœ‰å¯¹äº`__call__`çš„å®šä¹‰ï¼Œå…¶ä¸­è°ƒç”¨äº†`forward`å‡½æ•°ï¼Œå› æ­¤åªç”¨éšå¼è°ƒç”¨å°±å¯ä»¥è¿›è¡Œä¸€æ¬¡å‰å‘ä¼ æ’­çš„è®¡ç®—

```python
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
# æŸå¤±å‡½æ•°ï¼šå‡æ–¹è¯¯å·®ï¼ˆMean Squared Error, MSEï¼‰
criterion = nn.MSELoss()
# ä¼˜åŒ–å™¨ï¼šéšæœºæ¢¯åº¦ä¸‹é™ï¼ˆStochastic Gradient Descent, SGDï¼‰
# å‚æ•°ï¼šmodel.parameters()å°±æ˜¯æ¨¡å‹è¦å­¦ä¹ çš„wå’Œb
# lr=0.01æ˜¯å­¦ä¹ ç‡ï¼Œæ§åˆ¶æ¯æ¬¡è°ƒæ•´çš„æ­¥ä¼å¤§å°ï¼ˆå¤ªå¤§å®¹æ˜“è·‘åï¼Œå¤ªæ…¢å®¹æ˜“æ…¢ï¼‰
optimizer = optim.SGD(model.parameters(), lr=0.01)
```

```python
# ç¬¬å››éƒ¨åˆ†ï¼šè®­ç»ƒæ¨¡å‹ 
epochs = 1000  
for epoch in range(epochs):
    # å‰å‘ä¼ æ’­ï¼šè®¡ç®—é¢„æµ‹å€¼
    predictions = model(x_train)
    
    # è®¡ç®—æŸå¤±ï¼šçœ‹é¢„æµ‹å¾—æœ‰å¤šå‡†
    loss = criterion(predictions, y_train)
    
    # åå‘ä¼ æ’­ï¼šæœ€å…³é”®çš„ä¸‰è¡Œä»£ç ï¼
    optimizer.zero_grad()  # 1. æ¸…ç©ºä¹‹å‰çš„æ¢¯åº¦ï¼ˆé˜²æ­¢ç´¯ç§¯ï¼‰
    loss.backward()        # 2. åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¢¯åº¦ï¼ˆè‡ªåŠ¨å¾®åˆ†ï¼ï¼‰
    optimizer.step()       # 3. æ›´æ–°å‚æ•°ï¼šw = w - lr * gradient
    
    # æ¯100è½®æ‰“å°ä¸€æ¬¡è¿›åº¦
    if (epoch+1) % 100 == 0:
        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')
        print(f'    w={model.linear.weight.item():.2f}, b={model.linear.bias.item():.2f}')
```

```python
# ç¬¬äº”éƒ¨åˆ†ï¼šæµ‹è¯•æ¨¡å‹
with torch.no_grad():  # æµ‹è¯•æ—¶ä¸éœ€è¦è®¡ç®—æ¢¯åº¦ï¼ŒèŠ‚çœå†…å­˜
    x_test = torch.tensor([[5.0], [6.0]])
    y_pred = model(x_test)
    print(f"\né¢„æµ‹ç»“æœï¼š")
    print(f"x=5 â†’ y={y_pred[0].item():.2f} (åº”è¯¥æ¥è¿‘11)")
    print(f"x=6 â†’ y={y_pred[1].item():.2f} (åº”è¯¥æ¥è¿‘13)")
```

```
initial parameters show:w=-0.04,b=0.87
Epoch [100/1000], Loss: 0.0231
    w=1.87, b=1.37
Epoch [200/1000], Loss: 0.0127
    w=1.91, b=1.27
Epoch [300/1000], Loss: 0.0070
    w=1.93, b=1.20
Epoch [400/1000], Loss: 0.0038
    w=1.95, b=1.15
Epoch [500/1000], Loss: 0.0021
    w=1.96, b=1.11
Epoch [600/1000], Loss: 0.0012
    w=1.97, b=1.08
Epoch [700/1000], Loss: 0.0006
    w=1.98, b=1.06
Epoch [800/1000], Loss: 0.0003
    w=1.98, b=1.05
Epoch [900/1000], Loss: 0.0002
    w=1.99, b=1.03
Epoch [1000/1000], Loss: 0.0001
    w=1.99, b=1.02

é¢„æµ‹ç»“æœï¼š
x=5 â†’ y=10.98 (åº”è¯¥æ¥è¿‘11)
x=6 â†’ y=12.97 (åº”è¯¥æ¥è¿‘13)
```

å¦‚æœå¸Œæœ›ä½¿ç”¨GPUæ¥è®­ç»ƒå’Œä¿å­˜æ¨¡å‹å‚æ•°ï¼Œå¿…é¡»ä¿è¯ï¼Œè®­ç»ƒå¼ é‡ã€æ¨¡å‹æƒé‡å‚æ•°ã€æµ‹è¯•å¼ é‡å…¨éƒ¨åŸºäºGPUï¼Œéœ€è¦åšä»¥ä¸‹ç»Ÿä¸€
```python
# åˆ›å»ºæ¨¡å‹å®ä¾‹
model = LinearRegressionModel()

# âœ… æ·»åŠ è¿™ä¸€è¡Œï¼ŒæŠŠæ¨¡å‹ç§»åˆ°GPU
model = model.to('cuda')

print(f"initial parameters show:w={model.linear.weight.item():.2f},b={model.linear.bias.item():.2f}")
```
```python
with torch.no_grad():
    x_test = torch.tensor([[5.0], [6.0]], device='cuda')  # åŠ ä¸Š device='cuda'
    y_pred = model(x_test)
   
```


å¦‚æœéœ€è¦ä¿è¯æ¡†æ¶ï¼Œå¯ä»¥é‡‡ç”¨é»˜è®¤å†ç§»åŠ¨çš„æ–¹å¼
```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# 1ï¼‰æ•°æ®ï¼šå…ˆæŒ‰æ™®é€šæ–¹å¼åˆ›å»ºï¼Œå†ç»Ÿä¸€ç§»åŠ¨
x_train = torch.tensor([[1.0], [2.0], [3.0], [4.0]])  # é»˜è®¤åœ¨ CPU
y_train = torch.tensor([[3.0], [5.0], [7.0], [9.0]])

x_train = x_train.to(device)
y_train = y_train.to(device)

# 2ï¼‰æ¨¡å‹ï¼šå…ˆåˆ›å»ºï¼Œå† .to(device)
model = LinearRegressionModel()      # é»˜è®¤åœ¨ CPU
model = model.to(device)            # ç§»åˆ° GPU

# 3ï¼‰æµ‹è¯•æ•°æ®åŒç†
x_test = torch.tensor([[5.0], [6.0]])
x_test = x_test.to(device)          # ä¹Ÿè¦ç§»è¿‡å»
```